{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print folder tree for giving pathimport os\n",
    "\n",
    "def print_folder_tree(path, indent=\"\"):\n",
    "    for item in os.listdir(path):\n",
    "        item_path = os.path.join(path, item)\n",
    "        print(indent + \"|-- \" + item)\n",
    "        if os.path.isdir(item_path):\n",
    "            print_folder_tree(item_path, indent + \"    \")\n",
    "\n",
    "# Set your desired path\n",
    "path = \"/Volumes/backup/Study Data/LV103 - BersonHackett Business Study/st1 - Dance Studio\"\n",
    "print_folder_tree(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all .hdf5 files in a folder\n",
    "import os\n",
    "\n",
    "def find_hdf5_files(folder_path):\n",
    "    \"\"\"\n",
    "    Recursively searches for .hdf5 files in a given folder path and returns their paths.\n",
    "\n",
    "    Parameters:\n",
    "        folder_path (str): The path to the folder where the search will start.\n",
    "\n",
    "    Returns:\n",
    "        list of str: A list of full paths to files with the .hdf5 extension.\n",
    "    \"\"\"\n",
    "    hdf5_files = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".hdf5\"):\n",
    "                hdf5_files.append(os.path.join(root, file))\n",
    "    return hdf5_files\n",
    "\n",
    "# Using your specified path\n",
    "folder_path = \"/Volumes/backup/Study Data/LV103 - BersonHackett Business Study/st1 - Dance Studio\"\n",
    "hdf5_files = find_hdf5_files(folder_path)\n",
    "\n",
    "# Print the found .hdf5 file paths\n",
    "for path in hdf5_files:\n",
    "    print(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-level groups and datasets:\n",
      "['AsynchronData', 'RawData', 'SavedFeatues', 'Version']\n",
      "\n",
      "AsynchronData/\n",
      "  |  |- AsynchronSignalTypes : (1,) |S1824\n",
      "  |  |- Time : (1, 1) int64\n",
      "  |  |- TypeID : (1, 1) int32\n",
      "  |  |- Value : (1, 1) int32\n",
      "RawData/\n",
      "  |  |- AcquisitionTaskDescription : (1,) |S5166\n",
      "  |  |- DAQDeviceCapabilities : (1,) |S25871\n",
      "  |  |- DAQDeviceDescription : (1,) |S357\n",
      "  |  |- Samples : (656155, 6) float32\n",
      "  |  |- SessionDescription : (1,) |S205\n",
      "  |  |- SubjectDescription : (1,) |S282\n",
      "SavedFeatues/\n",
      "  |  |- NumberOfFeatures : (1,) int32\n",
      "Version/\n",
      "  |  |- Version : (1,) |S3\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Load the data from the HDF5 file \n",
    "\n",
    "import h5py\n",
    "\n",
    "def navigate_hdf5(file_path):\n",
    "    with h5py.File(file_path, 'r') as file:\n",
    "        print(\"Top-level groups and datasets:\")\n",
    "        print(list(file.keys()))\n",
    "        print()\n",
    "        navigate_group(file)\n",
    "\n",
    "def navigate_group(group, prefix=\"\"):\n",
    "    for name, item in group.items():\n",
    "        if isinstance(item, h5py.Dataset):\n",
    "            print(prefix + '  |-', name, ':', item.shape, item.dtype)\n",
    "        elif isinstance(item, h5py.Group):\n",
    "            print(prefix + name + '/')\n",
    "            navigate_group(item, prefix=prefix + '  |')\n",
    "\n",
    "# Set the path to the HDF5 file\n",
    "file_path = '/Volumes/backup/Study Data/LV103 - BersonHackett Business Study/st1 - Dance Studio/Sep10/081_group01/physiology/dancestudio_day00_group01_lv103_0812024.09.10_11.46.30.hdf5'\n",
    "\n",
    "navigate_hdf5(file_path)\n",
    "# print a long line\n",
    "print('-' * 80)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'<?xml version=\"1.0\" encoding=\"utf-8\" ?>\\n<DAQDeviceDescription xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\">\\n  <Unit>uV</Unit>\\n  <MinValue>-250000</MinValue>\\n  <MaxValue>250000</MaxValue>\\n  <Vendor>Guger Technologies</Vendor>\\n  <Name>g.USBamp (UB-2012.10.22 UB-2012.10.23 )</Name>\\n</DAQDeviceDescription>']\n"
     ]
    }
   ],
   "source": [
    "# HDF5 file description\n",
    "description = physiology_raw['RawData']['DAQDeviceDescription'][()]\n",
    "print(description)\n",
    "\n",
    "'''[b'<?xml version=\"1.0\" encoding=\"utf-8\" ?>\\n\n",
    "<DAQDeviceDescription xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\">\\n\n",
    "  <Unit>uV</Unit>\\n\n",
    "      <MinValue>-250000</MinValue>\\n\n",
    "          <MaxValue>250000</MaxValue>\\n\n",
    "              <Vendor>Guger Technologies</Vendor>\\n\n",
    "                  <Name>g.USBamp (UB-2012.10.22 UB-2012.10.23 )</Name>\\n\n",
    "                  </DAQDeviceDescription>']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/Volumes/backup/Study Data/LV103 - BersonHackett Business Study/st1 - Dance Studio/Sep10/081_group01/physiology/dancestudio_day00_group01_lv103_0812024.09.10_11.46.30.hdf5'\n",
    "physiology_raw = h5py.File(file_path)\n",
    "\n",
    "samples = physiology_raw['RawData']['Samples']#[:]/ 10e6  # TODO slicing is for getting the data into a numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the first row of samples\n",
    "plt.plot(samples[1000:10000,0])\n",
    "plt.title('First Row of Samples')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neurokit2 as nk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process ecg\n",
    "ecg_signals, info = nk.ecg_process(samples[1000:10000,0], sampling_rate=256)\n",
    "\n",
    "nk.ecg_plot(ecg_signals[:3000], info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hanytawfik/miniforge3/envs/mne/lib/python3.11/site-packages/neurokit2/hrv/hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ECG_Rate_Mean</th>\n",
       "      <th>HRV_MeanNN</th>\n",
       "      <th>HRV_SDNN</th>\n",
       "      <th>HRV_SDANN1</th>\n",
       "      <th>HRV_SDNNI1</th>\n",
       "      <th>HRV_SDANN2</th>\n",
       "      <th>HRV_SDNNI2</th>\n",
       "      <th>HRV_SDANN5</th>\n",
       "      <th>HRV_SDNNI5</th>\n",
       "      <th>HRV_RMSSD</th>\n",
       "      <th>...</th>\n",
       "      <th>HRV_SampEn</th>\n",
       "      <th>HRV_ShanEn</th>\n",
       "      <th>HRV_FuzzyEn</th>\n",
       "      <th>HRV_MSEn</th>\n",
       "      <th>HRV_CMSEn</th>\n",
       "      <th>HRV_RCMSEn</th>\n",
       "      <th>HRV_CD</th>\n",
       "      <th>HRV_HFD</th>\n",
       "      <th>HRV_KFD</th>\n",
       "      <th>HRV_LZC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91.778481</td>\n",
       "      <td>[[167.37735849056602]]</td>\n",
       "      <td>[[8.66741558298919]]</td>\n",
       "      <td>[[nan]]</td>\n",
       "      <td>[[nan]]</td>\n",
       "      <td>[[nan]]</td>\n",
       "      <td>[[nan]]</td>\n",
       "      <td>[[nan]]</td>\n",
       "      <td>[[nan]]</td>\n",
       "      <td>[[7.828694753179583]]</td>\n",
       "      <td>...</td>\n",
       "      <td>[[2.5649493574615367]]</td>\n",
       "      <td>[[4.477643803497341]]</td>\n",
       "      <td>[[1.439328722528385]]</td>\n",
       "      <td>[[1.0435968174739092]]</td>\n",
       "      <td>[[0.0]]</td>\n",
       "      <td>[[0.0]]</td>\n",
       "      <td>[[1.8915854127621117]]</td>\n",
       "      <td>[[1.89902066156178]]</td>\n",
       "      <td>[[2.952573814071125]]</td>\n",
       "      <td>[[1.0807397084081507]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ECG_Rate_Mean              HRV_MeanNN              HRV_SDNN HRV_SDANN1  \\\n",
       "0     91.778481  [[167.37735849056602]]  [[8.66741558298919]]    [[nan]]   \n",
       "\n",
       "  HRV_SDNNI1 HRV_SDANN2 HRV_SDNNI2 HRV_SDANN5 HRV_SDNNI5  \\\n",
       "0    [[nan]]    [[nan]]    [[nan]]    [[nan]]    [[nan]]   \n",
       "\n",
       "               HRV_RMSSD  ...              HRV_SampEn             HRV_ShanEn  \\\n",
       "0  [[7.828694753179583]]  ...  [[2.5649493574615367]]  [[4.477643803497341]]   \n",
       "\n",
       "             HRV_FuzzyEn                HRV_MSEn HRV_CMSEn HRV_RCMSEn  \\\n",
       "0  [[1.439328722528385]]  [[1.0435968174739092]]   [[0.0]]    [[0.0]]   \n",
       "\n",
       "                   HRV_CD               HRV_HFD                HRV_KFD  \\\n",
       "0  [[1.8915854127621117]]  [[1.89902066156178]]  [[2.952573814071125]]   \n",
       "\n",
       "                  HRV_LZC  \n",
       "0  [[1.0807397084081507]]  \n",
       "\n",
       "[1 rows x 83 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract ECG features\n",
    "nk.ecg_intervalrelated(ecg_signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
